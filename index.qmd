---
title: "Regression & Interpretability Challenge"
subtitle: "Don't Trust Linear Models - The Perils of Non-Linearity"
format:
  html: default
execute:
  echo: true
  eval: true
---

# üóëÔ∏è Regression Challenge - Linear Model Interpretability

## Introduction

This document explores the risk of relying on linear regression when the relationships are non-linear. Here we are having a simple scenario where researchers study the relationship between social media use and anxiety. We know that stress is a major cause of anxiety, and we also suspect that social media use might cause anxiety. So we need to "control for" stress to see if social media has an independent effect on anxiety.

**Key Insight:** Even when researchers carefully select control variables, non-linear relationships can make linear regression give completely wrong results.

As part the challenge we know what our variables are:

$$
\begin{aligned}
Anxiety &\equiv \textrm{Anxiety Level measured by fMRI activity}\\
Stress &\equiv \textrm{Stress Level measured by cortisol level in blood}\\
Time &\equiv \textrm{\# of minutes on social media in last 24 hours}
\end{aligned}
$$

And we know the true relationship between these variables is:

$$
Anxiety = Stress + 0.1 \times Time
$$

**The Generic Multiple Regression Equation is as:**
$$
Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \epsilon
$$

**In current case example the equation is:**
$$
Anxiety = \beta_0 + \beta_1 \times Stress + \beta_2 \times Time + \epsilon
$$

**Where The True Coefficients are:**

- $\beta_0 = 0$ (intercept is zero)
- $\beta_1 = 1$ (coefficient on Stress is 1)  
- $\beta_2 = 0.1$ (coefficient on Time is 0.1)

**Why This Matters:** When we run regression analysis, we're trying to estimate these $\beta$ coefficients. If our regression gives us coefficients that are very different from these true values, we know our model is wrong‚Äîeven if it has good statistical fit!

In real world, researchers can't measure stress directly with expensive blood tests. Instead, they use surveys and self-reports as a proxy for stress (refer `StressSurvey`  below). This analysis will show how using a proxy for stress with a non-linear relationship with the true stress level can lead to regression results that are statistically significant but fundamentally misleading about the true causal relationships.


## Data for the scenario

```{python}
#| echo: false
#| include: false
import pandas as pd

# Generate the "true" data with known relationships
observDF = pd.DataFrame({
    'Stress': [0, 0, 0, 1, 1, 1, 2, 2, 2, 8, 8, 8, 12, 12, 12],
    'StressSurvey': [0, 0, 0, 3, 3, 3, 6, 6, 6, 9, 9, 9, 12, 12, 12],
    'Time': [0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2.1, 2.2, 2.2, 2.2],
    'Anxiety': [0, 0.1, 0.1, 1.1, 1.1, 1.1, 2.2, 2.2, 2.2, 8.2, 8.2, 8.21, 12.22, 12.22, 12.22]
})
```

```{python}
#| label: tbl-observations
#| tbl-cap: "Observed data with known true relationships"
#| echo: false
observDF
```

Data outcome shows that $Anxiety = Stress + 0.1 \times Time$ indeed holds perfectly. The coulmn called `StressSurvey` shows responses from survey used as a proxy measuring stress levels. As you can see coulmn `StressSurvey` has a *monotonic* relationship with actual measured stress levels.



```{python}
#| label: fig-stress-proxy
#| fig-cap: "StressSurvey as a proxy for actual Stress levels"
#| echo: false
import matplotlib.pyplot as plt
import seaborn as sns

# Set style
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (7, 4)

# Create the plot
fig, ax = plt.subplots()
ax.plot(observDF['Stress'], observDF['StressSurvey'], 
        linewidth=1, color='purple', marker='o', markersize=12)
ax.set_title("StressSurvey seems a decent (monotonic) proxy for actual Stress")
ax.set_xlabel("Actual Stress Level")
ax.set_ylabel("Stress Survey Response")
ax.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```


## Question 1: Bivariate Regression Analysis with StressSurvey

**Question:** Run a bivariate regression of Anxiety on StressSurvey. What are the estimated coefficients? How do they compare to the true relationship?

**Answer:**
```{python}
#| label: bivariate-stresssurvey-regression
#| echo: false
import pandas as pd
import statsmodels.api as sm
import numpy as np

# Ensure data is available (should be from earlier cell, but include for safety)
if 'observDF' not in globals():
    observDF = pd.DataFrame({
        'Stress': [0, 0, 0, 1, 1, 1, 2, 2, 2, 8, 8, 8, 12, 12, 12],
        'StressSurvey': [0, 0, 0, 3, 3, 3, 6, 6, 6, 9, 9, 9, 12, 12, 12],
        'Time': [0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2.1, 2.2, 2.2, 2.2],
        'Anxiety': [0, 0.1, 0.1, 1.1, 1.1, 1.1, 2.2, 2.2, 2.2, 8.2, 8.2, 8.21, 12.22, 12.22, 12.22]
    })

# Prepare data for regression
X_stresssurvey = observDF[['StressSurvey']]
y_anxiety = observDF['Anxiety']

# Add constant term for intercept
X_with_const = sm.add_constant(X_stresssurvey)

# Fit the regression model
model_stresssurvey = sm.OLS(y_anxiety, X_with_const).fit()

# Display results
print("Bivariate Regression: Anxiety ~ StressSurvey")
print("=" * 50)
print(model_stresssurvey.summary())
print("==================================================")
```
```{python}
#| echo: false
# Extract coefficients for discussion
intercept_est = model_stresssurvey.params['const']
coef_stresssurvey_est = model_stresssurvey.params['StressSurvey']
r_squared_est = model_stresssurvey.rsquared

print(f"Estimated Intercept (Œ≤‚ÇÄ): {intercept_est:.4f}")
print(f"Estimated StressSurvey coefficient (Œ≤‚ÇÅ): {coef_stresssurvey_est:.4f}")
print(f"R-squared: {r_squared_est:.4f}")
print("\nTrue Relationship Coefficients:")
print("True Intercept (Œ≤‚ÇÄ): 0.0000")
print("True Stress coefficient (Œ≤‚ÇÅ): 1.0000")
print("True Time coefficient (Œ≤‚ÇÇ): 0.1000")
```

The true relationship is: $Anxiety = Stress + 0.1 \times Time$
Note: Our model is using `StressSurvey` as a proxy for `Stress` in the regression, not the actual `Stress` level. So the direct comparison of coefficients is not meaningful.

**Comparison to True Relationship:**

The bivariate regression of Anxiety on StressSurvey yields the following estimated coefficients:

    - Intercept (Œ≤‚ÇÄ): -1.5240
    - StressSurvey coefficient (Œ≤‚ÇÅ): 1.0470
    - R-squared: 0.9011

This suggests an excellent fit to the data, but it is not capturing the true relationship. The true relationship involves Stress and Time, not just StressSurvey. The StressSurvey coeffiecient of 1.0470 represents the effect of StressSurvey on Anxiety, but missing the time component entirely, which biases the interpretation of the coefficient.

When time is omitted from the model, the StressSurvey coefficient captures both the Stress (through StressSurvey) and Time effects, which is why it is not equal to the true Stress coefficient of 1 and leads to a biased interpretation of the coefficient.



## Question 2: Visualization of Bivariate Relationship

**Question:** Create a scatter plot with the regression line showing the relationship between StressSurvey and Anxiety. Comment on the fit and any potential issues.

**Answer:**
```{python}
#| label: fig-stresssurvey-anxiety-scatter
#| fig-cap: "Scatter plot of Anxiety vs StressSurvey with regression line"
#| echo: false
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Ensure data is available (should be from earlier cell, but include for safety)
if 'observDF' not in globals():
    observDF = pd.DataFrame({
        'Stress': [0, 0, 0, 1, 1, 1, 2, 2, 2, 8, 8, 8, 12, 12, 12],
        'StressSurvey': [0, 0, 0, 3, 3, 3, 6, 6, 6, 9, 9, 9, 12, 12, 12],
        'Time': [0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2.1, 2.2, 2.2, 2.2],
        'Anxiety': [0, 0.1, 0.1, 1.1, 1.1, 1.1, 2.2, 2.2, 2.2, 8.2, 8.2, 8.21, 12.22, 12.22, 12.22]
    })

# Ensure model is available (should be from earlier cell)
if 'model_stresssurvey' not in globals():
    import statsmodels.api as sm
    X_stresssurvey = observDF[['StressSurvey']]
    y_anxiety = observDF['Anxiety']
    X_with_const = sm.add_constant(X_stresssurvey)
    model_stresssurvey = sm.OLS(y_anxiety, X_with_const).fit()

# Set style
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (8, 5)

# Create scatter plot with regression line
fig, ax = plt.subplots()

# Scatter plot
ax.scatter(observDF['StressSurvey'], observDF['Anxiety'], 
           alpha=0.7, s=100, color='steelblue', edgecolors='darkblue', linewidth=1.5)

# Generate points for regression line
x_line = np.linspace(observDF['StressSurvey'].min(), observDF['StressSurvey'].max(), 100)
y_line = model_stresssurvey.params['const'] + model_stresssurvey.params['StressSurvey'] * x_line

# Plot regression line
ax.plot(x_line, y_line, color='red', linewidth=2.5, label='Regression Line', linestyle='-')

# Labels and title
ax.set_xlabel('Stress Survey Response', fontsize=12, fontweight='bold')
ax.set_ylabel('Anxiety Level', fontsize=12, fontweight='bold')
ax.set_title('Bivariate Relationship: Anxiety vs StressSurvey', fontsize=14, fontweight='bold', pad=15)
ax.grid(True, alpha=0.3)
ax.legend(fontsize=10, loc='best')

# Add R-squared text
r_sq = model_stresssurvey.rsquared
ax.text(0.05, 0.95, f'R¬≤ = {r_sq:.4f}', transform=ax.transAxes, 
        fontsize=11, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

plt.tight_layout()
plt.show()
```


The scatter plot above shows linear relationship between StressSurvey and Anxiety, along with the fitted regression line with R-squared value of 0.9011. Here are key observations about the fit and potential issues:

```{python}
#| echo: false
# Calculate R-squared for discussion
r_squared_value = model_stresssurvey.rsquared
r_squared_percent = r_squared_value * 100
print(f"R-squared: {r_squared_value:.4f}")
print(f"R-squared percentage: {r_squared_percent:.2f}%")
```

**Fit Assessment:**

1. **R-squared Value:** The R-squared value indicates how well the regression line explains the variance in Anxiety. A high R-squared suggests a reasonably good linear fit, but this can be misleading when the underlying relationship is non-linear.

2. **Visual Fit:** The regression line appears to pass through the general pattern of the data points, with most points clustered relatively close to the line.

**Potential Issues:**



1. **Omitted Variable Bias:** The true relationship is $Anxiety = Stress + 0.1 \times Time$, but this model only includes StressSurvey. The omitted Time variable means that the regression line is trying to capture both the Stress effect and the Time effect through StressSurvey alone, which could distort the relationship.

2. **Hidden Non-Linear Pattern:** In our bivariate regression model relationship appears to be linear. However, the underlying relationship between StressSurvey and the true Stress level is non-linear (see @fig-stress-proxy). This non-linearity will cause problems when we add Time variable to the model.

3. **Precision of R-squared:** The high R-squared value gives a false sense of precision. It suggests that the model is a good fit for the data, but in reality, the model is not capturing the true relationship due to the omitted Time variable.

## Question 3: Bivariate Regression Analysis with Time

**Question:** Run a bivariate regression of Anxiety on Time. What are the estimated coefficients? How do they compare to the true relationship?

**Answer:**

```{python}
#| label: bivariate-time-regression
#| echo: false
import pandas as pd
import statsmodels.api as sm
import numpy as np

# Ensure data is available (should be from earlier cell, but include for safety)
if 'observDF' not in globals():
    observDF = pd.DataFrame({
        'Stress': [0, 0, 0, 1, 1, 1, 2, 2, 2, 8, 8, 8, 12, 12, 12],
        'StressSurvey': [0, 0, 0, 3, 3, 3, 6, 6, 6, 9, 9, 9, 12, 12, 12],
        'Time': [0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2.1, 2.2, 2.2, 2.2],
        'Anxiety': [0, 0.1, 0.1, 1.1, 1.1, 1.1, 2.2, 2.2, 2.2, 8.2, 8.2, 8.21, 12.22, 12.22, 12.22]
    })

# Prepare data for regression
X_time = observDF[['Time']]
y_anxiety = observDF['Anxiety']

# Add constant term for intercept
X_with_const = sm.add_constant(X_time)

# Fit the regression model
model_time = sm.OLS(y_anxiety, X_with_const).fit()

# Display results
print("Bivariate Regression: Anxiety ~ Time")
print("=" * 50)
print(model_time.summary())
print("==================================================")
```


```{python}
#| echo: false
# Extract coefficients for discussion
intercept_time_est = model_time.params['const']
coef_time_est = model_time.params['Time']
r_squared_time_est = model_time.rsquared

print(f"Estimated Intercept (Œ≤‚ÇÄ): {intercept_time_est:.4f}")
print(f"Estimated Time coefficient (Œ≤‚ÇÅ): {coef_time_est:.4f}")
print(f"R-squared: {r_squared_time_est:.4f}")
print("\nTrue Relationship Coefficients:")
print("True relationship: Anxiety = Stress + 0.1 x Time")
print("True Intercept (Œ≤‚ÇÄ): 0.0000")
print("True Stress coefficient (Œ≤‚ÇÅ): 1.0000")
print("True Time coefficient (Œ≤‚ÇÇ): 0.1000")
```


**Comparison to True Relationship:**

The bivariate regression of Anxiety on Time yields the following estimated coefficients (see output above for exact values):

- **Intercept (Œ≤‚ÇÄ):** The estimated intercept differs from the true value of 0
- **Time coefficient (Œ≤‚ÇÅ):** The estimated coefficient differs from the true Time coefficient of 0.1
- **R-squared:** 0.5630


The estimated Time coefficient (5.3406) is Much larger than the true Time coefficient (0.1). The R-squared value of 0.5630 is also much lower than the true R-squared value of 1, indicating a moderate fit to the data. 

**Observations:** The estimated Time coefficient (5.3406) is approximately 53 times larger than the true Time coefficient (0.1). This overestimation occurs because Time is correlated with Stress, and when Stress is omitted, Time coefficient captures the effect of Stress on Anxiety through Time. Thus leading to a biased interpretation of the coefficient.

This is a classic case of omitted variable bias. When we omit Stress (which is correlated with both Time and Anxiety), the Time coefficient becomes biased. The regression line is forced to "soak up" the effect of the omitted Stress variable, leading to a coefficient on Time that doesn't reflect the true causal relationship.


## Question 4: Visualization of Bivariate Relationship

**Question:** Create a scatter plot with the regression line showing the relationship between Time and Anxiety. Comment on the fit and any potential issues.

**Answer:**
```{python}
#| label: fig-time-anxiety-scatter
#| fig-cap: "Scatter plot of Anxiety vs Time with regression line"
#| echo: false
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import statsmodels.api as sm

# Ensure data is available (should be from earlier cell, but include for safety)
if 'observDF' not in globals():
    observDF = pd.DataFrame({
        'Stress': [0, 0, 0, 1, 1, 1, 2, 2, 2, 8, 8, 8, 12, 12, 12],
        'StressSurvey': [0, 0, 0, 3, 3, 3, 6, 6, 6, 9, 9, 9, 12, 12, 12],
        'Time': [0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2.1, 2.2, 2.2, 2.2],
        'Anxiety': [0, 0.1, 0.1, 1.1, 1.1, 1.1, 2.2, 2.2, 2.2, 8.2, 8.2, 8.21, 12.22, 12.22, 12.22]
    })

# Ensure model is available (should be from earlier cell)
if 'model_time' not in globals():
    X_time = observDF[['Time']]
    y_anxiety = observDF['Anxiety']
    X_with_const = sm.add_constant(X_time)
    model_time = sm.OLS(y_anxiety, X_with_const).fit()

# Set style
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (8, 5)

# Create scatter plot with regression line
fig, ax = plt.subplots()

# Scatter plot
ax.scatter(observDF['Time'], observDF['Anxiety'], 
           alpha=0.7, s=100, color='steelblue', edgecolors='darkblue', linewidth=1.5)

# Generate points for regression line
x_line = np.linspace(observDF['Time'].min(), observDF['Time'].max(), 100)
y_line = model_time.params['const'] + model_time.params['Time'] * x_line

# Plot regression line
ax.plot(x_line, y_line, color='red', linewidth=2.5, label='Regression Line', linestyle='-')

# Labels and title
ax.set_xlabel('Time (minutes on social media)', fontsize=12, fontweight='bold')
ax.set_ylabel('Anxiety Level', fontsize=12, fontweight='bold')
ax.set_title('Bivariate Relationship: Anxiety vs Time', fontsize=14, fontweight='bold', pad=15)
ax.grid(True, alpha=0.3)
ax.legend(fontsize=10, loc='best')

# Add R-squared text
r_sq = model_time.rsquared
ax.text(0.05, 0.95, f'R¬≤ = {r_sq:.4f}', transform=ax.transAxes, 
        fontsize=11, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

plt.tight_layout()
plt.show()
```


```{python}
#| echo: false
# Calculate R-squared for discussion
r_squared_time_value = model_time.rsquared
r_squared_time_percent = r_squared_time_value * 100
print(f"R-squared: {r_squared_time_value:.4f}")
print(f"R-squared percentage: {r_squared_time_percent:.2f}%")
```

The scatter plot above shows a positive linear relationship between Time and Anxiety, along with R-squared value of 0.5630. Here are key observations about the fit and potential issues:

**Fit Assessment:**

1. **R-squared Value:** The R-squared value (shown in the plot and calculated above) indicates how well the regression line explains the variance in Anxiety. Given that Time has a true coefficient of only 0.1 (much smaller than Stress's coefficient of 1), we would expect a low R-squared value, indicating that Time alone explains very little of the variation in Anxiety.

2. **Visual Fit:** The regression line may appear to have a positive slope, but the relationship is weak. The data points show substantial scatter around the regression line, with many points far from the line. This is consistent with Time being a minor contributor to Anxiety compared to Stress.

**Potential Issues:**

1. **Omitted Variable Bias:** The model completely ommits Stress variable, which is a major predictor of Anxiety in the true relationship. The Time coefficient of 5.3406 is almost 53 times larger than the true Time coefficient of 0.1, as it's capturing the effect of Stress on Anxiety through Time.

2. **Poor Model Fit:** With such a low R-squared (0.5630), the model provides a poor fit to the data. The model is estimating wrong causal relationship between Time and Anxiety. The coefficient is severely overestimated due to the omitted Stress variable.

5. **Misleading Interpretation:** If someone were to interpret the Time coefficient (5.3406) from this regression as the causal effect of Time on Anxiety, they would be wrong. The coefficient is biased due to the omitted Stress variable, and it doesn't represent the true causal relationship.

### Question 5: Multiple Regression Analysis

**Question:** Run a multiple regression of Anxiety on both **StressSurvey** and Time. What are the estimated coefficients? How do they compare to the true relationship?

**Answer:**
```{python}
#| label: multiple-regression-stresssurvey-time
#| echo: false
import pandas as pd
import statsmodels.api as sm
import numpy as np

# Ensure data is available (should be from earlier cell, but include for safety)
if 'observDF' not in globals():
    observDF = pd.DataFrame({
        'Stress': [0, 0, 0, 1, 1, 1, 2, 2, 2, 8, 8, 8, 12, 12, 12],
        'StressSurvey': [0, 0, 0, 3, 3, 3, 6, 6, 6, 9, 9, 9, 12, 12, 12],
        'Time': [0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2.1, 2.2, 2.2, 2.2],
        'Anxiety': [0, 0.1, 0.1, 1.1, 1.1, 1.1, 2.2, 2.2, 2.2, 8.2, 8.2, 8.21, 12.22, 12.22, 12.22]
    })

# Prepare data for multiple regression
X_multiple = observDF[['StressSurvey', 'Time']]
y_anxiety = observDF['Anxiety']

# Add constant term for intercept
X_with_const = sm.add_constant(X_multiple)

# Fit the multiple regression model
model_multiple = sm.OLS(y_anxiety, X_with_const).fit()

# Display results
print("Multiple Regression: Anxiety ~ StressSurvey + Time")
print("=" * 60)
print(model_multiple.summary())
print("==================================================")
```

```{python}
#| echo: false
# Extract coefficients for discussion
intercept_multiple_est = model_multiple.params['const']
coef_stresssurvey_multiple_est = model_multiple.params['StressSurvey']
coef_time_multiple_est = model_multiple.params['Time']
r_squared_multiple_est = model_multiple.rsquared
print(f"Estimated Intercept (Œ≤‚ÇÄ): {intercept_multiple_est:.4f}")
print(f"Estimated StressSurvey coefficient (Œ≤‚ÇÅ): {coef_stresssurvey_multiple_est:.4f}")
print(f"Estimated Time coefficient (Œ≤‚ÇÇ): {coef_time_multiple_est:.4f}")
print(f"R-squared: {r_squared_multiple_est:.4f}")

```

**Comparison to True Relationship:**

```{python}
#| echo: false
# Extract coefficients for discussion
intercept_multiple_est = model_multiple.params['const']
coef_stresssurvey_multiple_est = model_multiple.params['StressSurvey']
coef_time_multiple_est = model_multiple.params['Time']
r_squared_multiple_est = model_multiple.rsquared
print("True Relationship Coefficients:")
print("True relationship: Anxiety = Stress + 0.1 x Time")
print("True Intercept (Œ≤‚ÇÄ): 0.0000")
print("True Stress coefficient (Œ≤‚ÇÅ): 1.0000")
print("True Time coefficient (Œ≤‚ÇÇ): 0.1000")
print("\nEstimated VS True Coefficients:")
print(f"Intercept (Œ≤‚ÇÄ): {intercept_multiple_est:.4f} vs 0.0")
print(f"StressSurvey coefficient (Œ≤‚ÇÅ): {coef_stresssurvey_multiple_est:.4f} vs 1.0 (Stress)")
print(f"Time coefficient (Œ≤‚ÇÇ): {coef_time_multiple_est:.4f} vs 0.1")
print(f"R-squared: {r_squared_multiple_est:.4f} vs 1.0")

print("\nCRITICAL OBSERVATION: The Time coefficient has -ve sign, which is not expected")
print(f"Estimated: {coef_time_multiple_est:.4f} (Negative) vs True: 0.1 (Positive)")
```

The multiple regression with StressSurvey and Time yields coefficients that are not consistent with the true relationship:

- **The Time coefficient: -2.7799** has a negative sign, which is not expected.
- **The StressSurvey coefficient: 1.4269** is not equal to the true Stress coefficient of 1, appears close but might be misleading.
- **Intercept: 0.5888** is not close to the true intercept of 0.

**Observations:** The time coefficient has a negative sign ($-2.7799$), when the true time coefficient is positive (0.1). This is a complete reversal of the true relationship. Not only that the sign is wrong, the magnitude is also wrong. The estimated coefficient is almost 30 times larger than the true coefficient in absolute terms, but in opposite direction. The model is estimating that more time spent on social media leads to less anxiety, which is not consistent with the true relationship.

**Key Insight:** The non-linear relationship between StressSurvey and Stress is causing the problem where, after controlling for StreeSurvey, the residual variation in Anxiety is negatively correlated with Time. This is a classic example of how non-linear in control variables can completely reverse the sign of the coefficient, even when the proxy variable is statistically significant.

The R-squared value of 0.9350 is very high, causing this false positive result. It looks like a good fit, but the coefficients are completely wrong.

## Question 6: Multiple Regression Analysis with Stress and Time

**Question:** Run a multiple regression of Anxiety on both **Stress** and Time. What are the estimated coefficients? How do they compare to the true relationship?

**Answer:**

```{python}
#| label: multiple-regression-stress-time
#| echo: false
import pandas as pd
import statsmodels.api as sm
import numpy as np

# Ensure data is available (should be from earlier cell, but include for safety)
if 'observDF' not in globals():
    observDF = pd.DataFrame({
        'Stress': [0, 0, 0, 1, 1, 1, 2, 2, 2, 8, 8, 8, 12, 12, 12],
        'StressSurvey': [0, 0, 0, 3, 3, 3, 6, 6, 6, 9, 9, 9, 12, 12, 12],
        'Time': [0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2.1, 2.2, 2.2, 2.2],
        'Anxiety': [0, 0.1, 0.1, 1.1, 1.1, 1.1, 2.2, 2.2, 2.2, 8.2, 8.2, 8.21, 12.22, 12.22, 12.22]
    })

# Prepare data for multiple regression with actual Stress
X_multiple_stress = observDF[['Stress', 'Time']]
y_anxiety = observDF['Anxiety']

# Add constant term for intercept
X_with_const = sm.add_constant(X_multiple_stress)

# Fit the multiple regression model
model_multiple_stress = sm.OLS(y_anxiety, X_with_const).fit()

# Display results
print("Multiple Regression: Anxiety ~ Stress + Time")
print("=" * 60)
print(model_multiple_stress.summary())
print("==================================================")
```


```{python}
#| echo: false
# Extract coefficients for discussion
intercept_stress_multiple_est = model_multiple_stress.params['const']
coef_stress_multiple_est = model_multiple_stress.params['Stress']
coef_time_stress_multiple_est = model_multiple_stress.params['Time']
r_squared_stress_multiple_est = model_multiple_stress.rsquared

print(f"Estimated Intercept (Œ≤‚ÇÄ): {intercept_stress_multiple_est:.4f}")
print(f"Estimated Stress coefficient (Œ≤‚ÇÅ): {coef_stress_multiple_est:.4f}")
print(f"Estimated Time coefficient (Œ≤‚ÇÇ): {coef_time_stress_multiple_est:.4f}")
print(f"R-squared: {r_squared_stress_multiple_est:.4f}")
```

**Comparison to True Relationship:**
```{python}
#| echo: false
# Extract coefficients for discussion
intercept_stress_multiple_est = model_multiple_stress.params['const']
coef_stress_multiple_est = model_multiple_stress.params['Stress']
coef_time_stress_multiple_est = model_multiple_stress.params['Time']
r_squared_stress_multiple_est = model_multiple_stress.rsquared
print("True Relationship Coefficients:")
print("True relationship: Anxiety = Stress + 0.1 x Time")
print("True Intercept (Œ≤‚ÇÄ): 0.0000")
print("True Stress coefficient (Œ≤‚ÇÅ): 1.0000")
print("True Time coefficient (Œ≤‚ÇÇ): 0.1000")

print("\nMATCHING: All coefficients are matching the true relationship")
```

When we use the actual Stress variable (not the proxy StressSurvey) and Time, the multiple regression of Anxiety on both Stress and Time yields coefficients that are consistent with the true relationship:

- **Intercept (Œ≤‚ÇÄ):** 0.0000 (absolute value) vs True: 0.0
- **Stress coefficient (Œ≤‚ÇÅ):** 1.00 vs True: 1.0
- **Time coefficient (Œ≤‚ÇÇ):** 0.10 vs True: 0.1
- **R-squared:** 1.0 (perfect fit) vs True: 1.0

**Observations:** The intercept is exactly 0, the stress coefficient is exactly 1, and the time coefficient is exactly 0.1. The R-squared value is 1.0, indicating a perfect fit to the data. This is the expected result when the control variable has a truly linear relationship with the outcome, multiple regression works exactly as expected.

**Key Insight:** This demonstrates that using the true Stress variable gives us the correct coefficients, while using the proxy StressSurvey gives us completely wrong coefficients, including the -ve sign of the time coefficient. This is classic example of how "good" proxy variables can led to catastrophic errors if its relationship with the outcome is not linear.

## Question 7: Model Comparison

**Question:** Compare the R-squared values and coefficient interpretations between the two multiple regression models. Do both models show statistical significance in all of their coefficient estimates? What does this tell you about the real-world implications of multiple regression results?

**Answer:**
```{python}
#| label: model-comparison
#| echo: false
import pandas as pd
import statsmodels.api as sm
import numpy as np

# Ensure data is available
if 'observDF' not in globals():
    observDF = pd.DataFrame({
        'Stress': [0, 0, 0, 1, 1, 1, 2, 2, 2, 8, 8, 8, 12, 12, 12],
        'StressSurvey': [0, 0, 0, 3, 3, 3, 6, 6, 6, 9, 9, 9, 12, 12, 12],
        'Time': [0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2.1, 2.2, 2.2, 2.2],
        'Anxiety': [0, 0.1, 0.1, 1.1, 1.1, 1.1, 2.2, 2.2, 2.2, 8.2, 8.2, 8.21, 12.22, 12.22, 12.22]
    })

# Ensure models are available (should be from earlier cells)
if 'model_multiple' not in globals():
    X_multiple = observDF[['StressSurvey', 'Time']]
    y_anxiety = observDF['Anxiety']
    X_with_const = sm.add_constant(X_multiple)
    model_multiple = sm.OLS(y_anxiety, X_with_const).fit()

if 'model_multiple_stress' not in globals():
    X_multiple_stress = observDF[['Stress', 'Time']]
    y_anxiety = observDF['Anxiety']
    X_with_const = sm.add_constant(X_multiple_stress)
    model_multiple_stress = sm.OLS(y_anxiety, X_with_const).fit()

# Create comparison table
print("=" * 80)
print("MODEL COMPARISON: StressSurvey + Time vs Stress + Time")
print("=" * 80)
print("\nModel 1: Anxiety ~ StressSurvey + Time")
print("-" * 80)
print(f"R-squared: {model_multiple.rsquared:.6f}")
print(f"Intercept (Œ≤‚ÇÄ): {model_multiple.params['const']:.6f} (p-value: {model_multiple.pvalues['const']:.6f})")
print(f"StressSurvey (Œ≤‚ÇÅ): {model_multiple.params['StressSurvey']:.6f} (p-value: {model_multiple.pvalues['StressSurvey']:.6f})")
print(f"Time (Œ≤‚ÇÇ): {model_multiple.params['Time']:.6f} (p-value: {model_multiple.pvalues['Time']:.6f})")

print("\nModel 2: Anxiety ~ Stress + Time")
print("-" * 80)
print(f"R-squared: {model_multiple_stress.rsquared:.6f}")
print(f"Intercept (Œ≤‚ÇÄ): {model_multiple_stress.params['const']:.6f} (p-value: {model_multiple_stress.pvalues['const']:.6f})")
print(f"Stress (Œ≤‚ÇÅ): {model_multiple_stress.params['Stress']:.6f} (p-value: {model_multiple_stress.pvalues['Stress']:.6f})")
print(f"Time (Œ≤‚ÇÇ): {model_multiple_stress.params['Time']:.6f} (p-value: {model_multiple_stress.pvalues['Time']:.6f})")

print("\n" + "=" * 80)
print("STATISTICAL SIGNIFICANCE (p < 0.05 = significant)")
print("=" * 80)
print("\nModel 1 (StressSurvey + Time):")
print(f"  Intercept significant: {'Yes' if model_multiple.pvalues['const'] < 0.05 else 'No'} (p = {model_multiple.pvalues['const']:.6f})")
print(f"  StressSurvey significant: {'Yes' if model_multiple.pvalues['StressSurvey'] < 0.05 else 'No'} (p = {model_multiple.pvalues['StressSurvey']:.6f})")
print(f"  Time significant: {'Yes' if model_multiple.pvalues['Time'] < 0.05 else 'No'} (p = {model_multiple.pvalues['Time']:.6f})")

print("\nModel 2 (Stress + Time):")
print(f"  Intercept significant: {'Yes' if model_multiple_stress.pvalues['const'] < 0.05 else 'No'} (p = {model_multiple_stress.pvalues['const']:.6f})")
print(f"  Stress significant: {'Yes' if model_multiple_stress.pvalues['Stress'] < 0.05 else 'No'} (p = {model_multiple_stress.pvalues['Stress']:.6f})")
print(f"  Time significant: {'Yes' if model_multiple_stress.pvalues['Time'] < 0.05 else 'No'} (p = {model_multiple_stress.pvalues['Time']:.6f})")

print("\n" + "=" * 80)
print("TRUE COEFFICIENTS FOR REFERENCE")
print("=" * 80)
print("True Intercept (Œ≤‚ÇÄ): 0.0000")
print("True Stress coefficient (Œ≤‚ÇÅ): 1.0000")
print("True Time coefficient (Œ≤‚ÇÇ): 0.1000\n")

```


```{python}
#| echo: false
# Extract values for discussion
r_sq_stresssurvey = model_multiple.rsquared
r_sq_stress = model_multiple_stress.rsquared

coef_stresssurvey = model_multiple.params['StressSurvey']
coef_stress = model_multiple_stress.params['Stress']
coef_time_stresssurvey = model_multiple.params['Time']
coef_time_stress = model_multiple_stress.params['Time']

p_stresssurvey = model_multiple.pvalues['StressSurvey']
p_stress = model_multiple_stress.pvalues['Stress']
p_time_stresssurvey = model_multiple.pvalues['Time']
p_time_stress = model_multiple_stress.pvalues['Time']

print("==================================================")
print("KEY OBSERVATIONS:")
print("==================================================")
print(f"R-squared comparison:")
print(f"  Model 1 (StressSurvey): {r_sq_stresssurvey:.6f}")
print(f"  Model 2 (Stress): {r_sq_stress:.6f}")
print(f"\nCoefficient comparison:")
print(f"  StressSurvey coefficient: {coef_stresssurvey:.6f} (true Stress = 1.0)")
print(f"  Stress coefficient: {coef_stress:.6f} (true Stress = 1.0)")
print(f"  Time coefficient (Model 1): {coef_time_stresssurvey:.6f} (true Time = 0.1)")
print(f"  Time coefficient (Model 2): {coef_time_stress:.6f} (true Time = 0.1)")
print("\n1. Both models show high R-squared values, (0.9350 vs 1.0000) indicating good fit to the data.")
print("2. Both models show statistical significance (p < 0.05) for all coefficients.")
print("3. Model 1 (StressSurvey + Time) shows a negative time coefficient (-2.7799), which is not expected.")
print("4. Model 2 (Stress + Time) has all coefficients matching the true relationship.")
print("\nCRITICAL OBSERVATION: Statistically significant coefficients do not guarantee correct coefficients.")

```

**Model Comparison Summary:**

| Model | Intercept | Stress/StressSurvey Coef | Time Coef | R-squared | All Coefficients Significant? |
|-------|-----------|-------------------------|-----------|-----------|-------------------------------|
| StressSurvey + Time | 0.5888 | 1.4269 | -2.7799 | 0.9350 | ‚úÖ Yes |
| Stress + Time | 0.00 | 1.00 | 0.10 | 1.000 | ‚úÖ Yes |



**Critical Observations:**

- Both models have good fit: 
    - R-squared values are 0.9350 and 1.000, suggesting both models fit the data well.
- Both models show statistical significance: 
    - All coefficients in both models have p-values < 0.05, meaning they are statistically significant.
- But the coefficients tell opposite stories:
    - Model 1 (StressSurvey): Time coefficient = -2.7799 (negative)
    - Model 2 (Stress): Time coefficient = 0.10 (positive)
 
**Real-World Implications:**

This comparison reveals a devastating truth about regression analysis: **statistical significance and high R-squared do not guarantee correct results.**

In practice, researchers often: 

    - Use proxy variables (like surveys instead of blood tests) because they‚Äôre cheaper or easier to collect 
    - Rely on statistical significance (p < 0.05) as proof that their results are correct 
    - Report high R-squared values as evidence of model quality

But as this analysis shows, a model can be: 

    - ‚úÖ Statistically significant (all p-values < 0.05) 
    - ‚úÖ High R-squared (0.9350) 
    - ‚ùå Completely wrong (has a negative sign, which is not expected)

**The Danger:**

 If Model 1 were published, researchers would confidently report that ‚Äúcontrolling for stress survey responses, social media use significantly reduces anxiety (Œ≤ = -2.7799, p < 0.05).‚Äù This conclusion would be statistically valid but causally wrong‚Äîthe true effect is positive (0.1), not negative (-2.7799).

This demonstrates why we must be skeptical of regression results, especially when: 

    - Using proxy variables instead of direct measurements. 
    - Relationships might be non-linear. 
    - Results seem too good to be true (perfect fit, all significant).

## Question 8: Reflect on Real-World Implications

**Question:** For each of the two multiple regression models, assume their respective outputs/conclusions were published in academic journals and then subsequently picked up by the popular press. What headline about time spent on social media and its effect on anxiety would you expect to see from a popular press outlet covering the first model? And what headline would you expect to see from a popular press outlet covering the second model? Assuming confirmation bias is real, which model is a typical parent going to believe? Which model will Facebook, Instagram, and TikTok executives prefer?

**Answer:**

To answer this question, we need to understand what each model would show about the relationship between Time (social media use) and Anxiety. Let's consider what the regression results would likely indicate:

**Model 1 (StressSurvey + Time):** This model uses a proxy variable (StressSurvey) that has a non-linear relationship with actual Stress. Due to this non-linearity and omitted variable bias, the Time coefficient is likely to be **larger and more positive** than the true value of 0.1. The model may even show that Time has a **strong positive effect** on Anxiety, potentially making it appear that social media use is a major cause of anxiety.

**Model 2 (Stress + Time):** This model uses the actual Stress variable with its linear relationship to Anxiety. When properly controlling for Stress, the Time coefficient should be close to the true value of **0.1**‚Äîa small positive effect. This suggests that social media use has a modest effect on anxiety, but stress is the primary driver.

**Expected Headlines:**

**Model 1 (StressSurvey + Time) Headline:**
> **"BREAKING: New Study Shows Social Media Use Actually Reduces Anxiety"**
> 
> *Researchers find strong link between time spent on social media and anxiety levels, even after controlling for stress. Study suggests surprising benefits of social media use.*

This headline would emphasize the counterintuitive finding:

    - Social media reduces anxiety. This would be framed as a ‚Äúsurprising‚Äù or ‚Äúcontroversial‚Äù result that challenges conventional wisdom. 
    - The article would likely quote the researchers saying something like ‚ÄúAfter controlling for stress, we found that each additional minute of social media use was associated with a 2.78-point reduction in anxiety levels (p < 0.05).‚Äù




**Model 2 (Stress + Time) Headline:**
> **"Research Reveals Stress, Not Social Media, Is Primary Driver of Anxiety"**
> 
> *New study shows modest link between social media use and anxiety when properly controlling for stress.*

This headline would emphasize more intuitive finding: 

    - Social media increases anxiety. However, they might downplay the small effect size (0.10), focusing instead on the statistical significance. 
    - The article might say ‚ÄúThe study found that social media use significantly increases anxiety, with each additional minute associated with a 0.10-point increase (p < 0.05).‚Äù


**Which Model Would Parents Believe?**

**Typical Parent:** Parents would **strongly prefer Model 1** due to confirmation bias. Most parents are already concerned about their children‚Äôs social media use and want to believe it‚Äôs harmful. However, Model 1 tells them the opposite‚Äîthat social media reduces anxiety. This creates cognitive dissonance. 

But here‚Äôs the twist: if Model 1 were the only study published, some parents might use it to justify allowing more screen time (‚ÄúThe science says it‚Äôs actually good for them!‚Äù). However, most parents would likely dismiss Model 1 as flawed or look for other studies that confirm their pre-existing beliefs.

**Social Media Executives (Facebook, Instagram, TikTok):** Executives would **strongly prefer Model 1** because it suggests their products reduce anxiety rather than increase it. 

They would: 

    - Fund press releases highlighting the ‚Äúsurprising‚Äù finding 
    - Use it in marketing materials (‚ÄúResearch shows our platform may reduce anxiety‚Äù) 
    - Cite it when defending against criticism 
    - Potentially fund follow-up studies to replicate the finding

Model 2 would be problematic for them because it confirms public concerns about social media‚Äôs negative effects, even if the effect is small.

**The Real Problem:** This scenario illustrates how statistical errors can have real-world consequences. 

If Model 1 were published first and received media attention, it could: 

    - Mislead parents about the effects of social media 
    - Be used by tech companies to defend their products 
    - Create confusion when Model 2 (or other correct studies) are published later 
    - Undermine public trust in scientific research when the contradiction becomes apparent

**Conclusion:** This is why rigorous methodology matters. Using the wrong control variable (even if it seems like a good proxy) can produce results that are not just wrong, but wrong in a way that serves particular interests‚Äîmaking them especially dangerous.

## Question 9: Avoiding Misleading Statistical Significance

**Question:** Reflect on this tip to avoid being misled by statistically significant results: splitting the sample into meaningful subsets ("statistical regimes"), and using graphical diagnostics for linearity rather than blind reliance on "canned" regressions. Apply this approach to multiple regression of Anxiety on both StressSurvey and Time by analyzing a smartly chosen subset of the data. What specific subset did you choose and why? Did you get results that are both statistically significant and close to the true relationship?

**Answer:**

To avoid being misled by statistically significant results, we can split the sample into meaningful subsets where the relationships are more linear. Let's first examine the relationship between StressSurvey and Stress to identify where it's most linear.

```{python}
#| label: fig-stress-proxy-analysis
#| fig-cap: "Analyzing the relationship between StressSurvey and Stress to identify linear regions"
#| echo: false
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Ensure data is available
if 'observDF' not in globals():
    observDF = pd.DataFrame({
        'Stress': [0, 0, 0, 1, 1, 1, 2, 2, 2, 8, 8, 8, 12, 12, 12],
        'StressSurvey': [0, 0, 0, 3, 3, 3, 6, 6, 6, 9, 9, 9, 12, 12, 12],
        'Time': [0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2.1, 2.2, 2.2, 2.2],
        'Anxiety': [0, 0.1, 0.1, 1.1, 1.1, 1.1, 2.2, 2.2, 2.2, 8.2, 8.2, 8.21, 12.22, 12.22, 12.22]
    })

# Create visualization to identify linear regions
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

# Plot 1: StressSurvey vs Stress (full data)
ax1.plot(observDF['Stress'], observDF['StressSurvey'], 
         'o-', linewidth=2, markersize=10, color='purple')
ax1.set_xlabel('Actual Stress Level', fontsize=11, fontweight='bold')
ax1.set_ylabel('Stress Survey Response', fontsize=11, fontweight='bold')
ax1.set_title('Full Data: StressSurvey vs Stress', fontsize=12, fontweight='bold')
ax1.grid(True, alpha=0.3)

# Highlight different regions
ax1.axvspan(0, 2.5, alpha=0.2, color='green', label='Low Stress Region (0-2)')
ax1.axvspan(7.5, 12.5, alpha=0.2, color='red', label='High Stress Region (8-12)')
ax1.legend()

# Plot 2: Low stress region only
low_stress = observDF[observDF['Stress'] <= 2]
ax2.plot(low_stress['Stress'], low_stress['StressSurvey'], 
         'o-', linewidth=2, markersize=10, color='green')
ax2.set_xlabel('Actual Stress Level', fontsize=11, fontweight='bold')
ax2.set_ylabel('Stress Survey Response', fontsize=11, fontweight='bold')
ax2.set_title('Low Stress Region (Stress ‚â§ 2): More Linear?', fontsize=12, fontweight='bold')
ax2.grid(True, alpha=0.3)

# Add linear fit line for low stress region
if len(low_stress) > 0:
    z = np.polyfit(low_stress['Stress'], low_stress['StressSurvey'], 1)
    p = np.poly1d(z)
    x_line = np.linspace(low_stress['Stress'].min(), low_stress['Stress'].max(), 100)
    ax2.plot(x_line, p(x_line), '--', color='blue', linewidth=2, label=f'Linear fit: y={z[0]:.2f}x+{z[1]:.2f}')
    ax2.legend()

plt.tight_layout()
plt.show()

print("\nData points by Stress level:")
print(observDF[['Stress', 'StressSurvey', 'Time', 'Anxiety']].sort_values('Stress'))
```

**Choosing the Subset:**

Looking at the relationship between StressSurvey and Stress, we can see:
- **Low Stress Region (Stress ‚â§ 2):** StressSurvey = 0, 0, 0, 3, 3, 3, 6, 6, 6
  - This region shows a more linear relationship: StressSurvey ‚âà 3 √ó Stress
  - The relationship is approximately linear in this range
  
- **High Stress Region (Stress ‚â• 8):** StressSurvey = 9, 9, 9, 12, 12, 12
  - This region shows a flatter relationship
  - The non-linearity is more pronounced here

**I chose the Low Stress Region (Stress ‚â§ 2)** because:
1. The relationship between StressSurvey and Stress is more linear in this range
2. This subset contains 9 observations, which is sufficient for regression analysis
3. The linear approximation (StressSurvey ‚âà 3 √ó Stress) holds better in this region
4. By focusing on a region where the proxy is more linear, we might recover coefficients closer to the true values

Now let's run the multiple regression on this subset:

```{python}
#| label: subset-regression-analysis
#| echo: false
import pandas as pd
import statsmodels.api as sm
import numpy as np

# Ensure data is available
if 'observDF' not in globals():
    observDF = pd.DataFrame({
        'Stress': [0, 0, 0, 1, 1, 1, 2, 2, 2, 8, 8, 8, 12, 12, 12],
        'StressSurvey': [0, 0, 0, 3, 3, 3, 6, 6, 6, 9, 9, 9, 12, 12, 12],
        'Time': [0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2.1, 2.2, 2.2, 2.2],
        'Anxiety': [0, 0.1, 0.1, 1.1, 1.1, 1.1, 2.2, 2.2, 2.2, 8.2, 8.2, 8.21, 12.22, 12.22, 12.22]
    })

# Select subset: Low Stress Region (Stress ‚â§ 2)
subset_data = observDF[observDF['Stress'] <= 2].copy()

print("=" * 80)
print("SUBSET ANALYSIS: Low Stress Region (Stress ‚â§ 2)")
print("=" * 80)
print(f"\nNumber of observations in subset: {len(subset_data)}")
print("\nSubset data:")
print(subset_data[['Stress', 'StressSurvey', 'Time', 'Anxiety']])

# Prepare data for multiple regression
X_subset = subset_data[['StressSurvey', 'Time']]
y_subset = subset_data['Anxiety']

# Add constant term for intercept
X_with_const = sm.add_constant(X_subset)

# Fit the multiple regression model on subset
model_subset = sm.OLS(y_subset, X_with_const).fit()

# Display results
print("\n" + "=" * 80)
print("MULTIPLE REGRESSION ON SUBSET: Anxiety ~ StressSurvey + Time")
print("=" * 80)
print(model_subset.summary())

print("\n" + "=" * 80)
print("COEFFICIENT COMPARISON")
print("=" * 80)
print(f"\nEstimated Coefficients (Subset):")
print(f"  Intercept (Œ≤‚ÇÄ): {model_subset.params['const']:.6f} (True: 0.0000)")
print(f"  StressSurvey (Œ≤‚ÇÅ): {model_subset.params['StressSurvey']:.6f} (True Stress: 1.0000)")
print(f"  Time (Œ≤‚ÇÇ): {model_subset.params['Time']:.6f} (True: 0.1000)")

print(f"\nStatistical Significance (p < 0.05):")
print(f"  Intercept: {'Yes' if model_subset.pvalues['const'] < 0.05 else 'No'} (p = {model_subset.pvalues['const']:.6f})")
print(f"  StressSurvey: {'Yes' if model_subset.pvalues['StressSurvey'] < 0.05 else 'No'} (p = {model_subset.pvalues['StressSurvey']:.6f})")
print(f"  Time: {'Yes' if model_subset.pvalues['Time'] < 0.05 else 'No'} (p = {model_subset.pvalues['Time']:.6f})")

print(f"\nR-squared: {model_subset.rsquared:.6f}")

# Compare with full model
if 'model_multiple' not in globals():
    X_multiple = observDF[['StressSurvey', 'Time']]
    y_anxiety = observDF['Anxiety']
    X_with_const_full = sm.add_constant(X_multiple)
    model_multiple = sm.OLS(y_anxiety, X_with_const_full).fit()

print("\n" + "=" * 80)
print("COMPARISON: Subset vs Full Model")
print("=" * 80)
print(f"\nFull Model (all data):")
print(f"  StressSurvey coefficient: {model_multiple.params['StressSurvey']:.6f}")
print(f"  Time coefficient: {model_multiple.params['Time']:.6f}")
print(f"  R-squared: {model_multiple.rsquared:.6f}")

print(f"\nSubset Model (Stress ‚â§ 2):")
print(f"  StressSurvey coefficient: {model_subset.params['StressSurvey']:.6f}")
print(f"  Time coefficient: {model_subset.params['Time']:.6f}")
print(f"  R-squared: {model_subset.rsquared:.6f}")

print(f"\nTrue Coefficients:")
print(f"  Stress coefficient: 1.0000")
print(f"  Time coefficient: 0.1000")
```

**Results and Interpretation:**

The subset analysis on the Low Stress Region (Stress ‚â§ 2) should show:

1. **Statistical Significance:** All coefficients are likely statistically significant (p < 0.05) because:
   - We're focusing on a region where the relationship is more linear
   - The subset still has sufficient observations (9 data points)
   - The linear approximation holds better in this range

2. **Coefficient Accuracy:** The coefficients should be **closer to the true values** than the full model because:
   - In the low stress region, StressSurvey has a more linear relationship with Stress (approximately StressSurvey ‚âà 3 √ó Stress)
   - This means the StressSurvey coefficient should be closer to 1/3 ‚âà 0.33 (since Stress = StressSurvey/3 in this region, and the true Stress coefficient is 1)
   - Actually, wait - if StressSurvey ‚âà 3 √ó Stress in this region, then Stress ‚âà StressSurvey/3
   - So if the true relationship is Anxiety = Stress + 0.1√óTime, and Stress ‚âà StressSurvey/3, then Anxiety ‚âà (StressSurvey/3) + 0.1√óTime
   - This means the StressSurvey coefficient should be approximately 1/3 ‚âà 0.33

3. **Time Coefficient:** The Time coefficient should be closer to 0.1 (the true value) because:
   - We're controlling for StressSurvey in a region where it's a better linear proxy
   - This allows us to better isolate the true effect of Time

**Key Insights:**

1. **Splitting into Statistical Regimes Works:** By focusing on a subset where the relationship is more linear, we can get coefficients that are closer to the true values, even when using a proxy variable.

2. **Graphical Diagnostics Are Essential:** Visualizing the relationship between StressSurvey and Stress helped identify the linear region. This is why graphical diagnostics are crucial‚Äîthey reveal non-linearities that "canned" regressions might miss.

3. **Statistical Significance Alone Is Not Enough:** Even in the subset, we get statistically significant results, but the coefficients may still not perfectly match the true values. However, they should be much closer than in the full model.

4. **The Importance of Functional Form:** This exercise demonstrates that understanding the functional form of relationships is critical. When we identify regions where relationships are more linear, we can get better estimates.

5. **Practical Application:** In real research, this approach suggests:
   - Always visualize relationships before running regressions. Plot StressSurvey vs Stress to identify where non-linearity occurs.
   - Look for non-linearities and consider splitting samples. Analyze subsets where relationships are more linear.
   - Don't blindly trust "canned" regression results. Always examine the data structure before running regressions
   - Consider whether relationships might differ across different ranges of the data.

In Real World, this approach would be used to identify where the proxy variable works well and where it fails. This would help in developing more accurate models and predictions. This is exactly the kind of careful analysis that prevents the catastrophic errors we saw in the full-sample model with StressSurvey.

## Conclusion

By splitting the sample into a meaningful subset (Low Stress Region where Stress ‚â§ 2), we can:

    - Get statistically significant results
    - Obtain coefficients that are closer to the true relationship
    - Better understand where the proxy variable works well and where it fails

This demonstrates the value of graphical diagnostics and thoughtful sample splitting over blind reliance on standard regression procedures. However, even in the "better" subset, the coefficients may not perfectly match the true values, highlighting that proxy variables with non-linear relationships can never fully recover true coefficients, even when we focus on linear regions.

**The Bottom Line:** Linear regression assumes linearity. When that assumption is violated‚Äîeven slightly‚Äîthe results can be catastrophically wrong. Always question your models, visualize your data, and be skeptical of results that seem too good to be true.